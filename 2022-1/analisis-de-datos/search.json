[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "1INF03 - Análisis de Datos",
    "section": "",
    "text": "Apuntes del curso Análisis de Datos, dictado en la Pontificia Universidad Católica del Perú."
  },
  {
    "objectID": "semana-01.html",
    "href": "semana-01.html",
    "title": "Semana 03/21",
    "section": "",
    "text": "Será necesario hacer un grupo con otros estudiantes del curso, con quienes se comparta afinidad de investigación, para el proyecto final del curso, el cual se irá desarrollando a lo largo del curso.\nPython y R son complementatios, no es que uno sea mejor que el otro.\nEn el curso, usaremos Python en su mayoría, pero también se compartirá, después de clase, el código análogo ,en R, de lo que trabajemos.\nEn la unidades 4 y 5, es donde más podremos contrastar el uso de Python y R. De esa manera, uno tendría más claro qué lenguaje escoger al momento de iniciar algún proyecto particular.\nFechas de laboratorio\n\n\n9 abril\n23 abril\n7 mayo\n11 junio\n25 junio\n\nLas dirigidas (perhaps a veces pcs) de IOP se me cruzan con todos los labs, excepto por el primero."
  },
  {
    "objectID": "semana-01.html#metodología-kdd",
    "href": "semana-01.html#metodología-kdd",
    "title": "Semana 03/21",
    "section": "Metodología KDD",
    "text": "Metodología KDD\n\n¿Qué es un dato?\n\nEl dato es el valor de una característica/variable/atributo (edad, sexo, etc) de la población (población delimitada en espacio, tiempo, etc).\nProcesos paralelos\n\nVariable \\(\\Rightarrow\\) Variable aleatoria \\(\\Rightarrow\\) Dato\nPoblación \\(\\Rightarrow\\) Muestra \\(\\Rightarrow\\) Observación\n\nLa información parte de la unión de los datos recopilados.\n\nEs de utilidad para tomar decisiones.\nUn solo dato, por su cuenta, no nos da información.\n\nEl conocimiento es un conjunto de informaciones aplicadas, que permite preveer y planificar.\n\nLa información asociada a un contexto y una experiencia se convierte en conocimiento.\n\n\n\n\nDescripción de la metodología KDD\n\nKDD: Knowledge Discovery in Databases\nAlgunas definiciones:\n\n\nKnowledge Discovery in Databases is the non trivial process of identifying valid, novel, potentially useful, and utimately understandable patterns in data.\n\n\nNivel bajo de datos se refiere a datos que no nos dice nada, pero que podría servir para generar conocimiento a partir de estos datos.\n\n\n\nEtapas de la metodología KDD\n\nEsta metodología nos da pasos para cómo convertir datos en conocimiento.\nEstas etapas no son obligatorias … sirven de guía.\n\n\n\n\n\n\nEtapas de la metodología KDD\n\n\n\n\n\nEn la etapa selection, se reduce la cantidad de data, quedándonos con la data que nos va a servir para lograr el objetivo de nuestro análisis.\nImplica filtrar filas y/o columnas/variables de la data (entendida como data frame).\nRequiere el entendimiento del objetivo del análisis.\nLa parte de información surge en la etapa Patterns de la metodología KDD. Esa información requiere del bloque interpretation/evaluation (ver imagen) para convertirse en knowledge .\nEl paso de Transformed data a patterns es vía “Descriptive methods”.\n\n\n\n\n\n\nEtapas (más a detalle) de la metodología KDD\n\n\n\n\n\nLas flechas verticales indican que, a medida que avanzamos en las etapas, podemos volver al inicio para poder obtener nueva data que haya surgido la necesidad de requerir para el análisis.\nEl bloque Active DM (Data Mining) se refiere a que el proceso Data mining forma parte de TODO el proceso de 9 pasos (es otro enfoque).\nRegresar a cualquier paso es válido.\n\n\nPaso 1\n\nEs el paso principal.\nReunirse con los expertos del tema en que se va a trabajar. Se discuten cosas como\n\n¿Cómo sucede el fenómeno?\n¿Qué agentes intervienen con el fenómeno?\n¿Qué datos se recolectan (variables disponibles) o se pueden recolectar para el fenómeno?\n¿Para qué población se va a construir el proyecto?\n\nSe habla en lenguaje entendible para todos los expertos, no usando, por ejemplo, palabras particulares de Estadística.\nSe busca entender el negocio/problema.\nSe busca identificar la meta del proceso KDD desde la perspectiva del customer.\nEs más que nada un proceso cualitativo que servirá para formalizar el análisis futuro.\nEs recomendable crear una ficha resumen sobre este paso, donde se anota la información recopilada en la reunicón (o reuniones) con el customer.\n\nAsignar un experto del negocio como encargado del proyecto. Esta persona debe ir validando el avance del proyecto, en cada uno de los 9 pasos.\nAnotas una meta principal y las secundarias.\nUna vez completa esta ficha resumen es que podemos pasar al siguiente paso; debe redactarse, quedar como evidencia.\n\n\nPaso 2\n\nCreating a target data set.\nFiltramos la data para obtener un subconjunto, tanto en variables (columnas) y data samples (filas), al cual se le analizará durante pasos siguientes.\nNo se trata de la selección de variable que se realiza con código, por ejemplo la que busca explicar un fenómeno con las variables independientes.\nEsta selección no tiene que ver con la calidad de datos. Esa selección ocurrirá más adelante.\nFormalmente, estos filtros se realizan en base a criterios de inclusión/exclusión.\n\nPaso 3\n\nData cleaning and preprocessing.\nSe le dice también remover el ruido. Donde, el ruido hace referencia a los datos atípicos.\nSe ve la forma de trabajar los datos perdidos.\n\nPara construir un modelo, necesitamos lidiar primero con los datos perdidos.\nDependiendo del contexto, y requiriendo fundamento, se pueden imputar/reemplazar los datos vacíos por cero, la mediana de esa variable, etc.\nDesde el punto de vista de la profesora, máximo se debería imputar el 30% de los valores vacíos de una misma variable (que tiene varios valores vacíos). Pues, sino, se estaría trabajando con una variable ficticia, y podría así generar ruido en los resultados obtenidos.\nPero eso no es una regla. La decisión de imputación dependerá del contexto/fenómeno, y debe estar fundamentada numéricamente, además de tener sentido respecto al negocio.\n(Por ejemplo, si imputar una variable por cero tiene sentido en cierto contexto particular).\n\nDebido, en parte, a estas razones, es importante la comunicación constante con un experto del negocio.\n\nPaso 4\n\nData reduction and projection.\nLa transformación de la data debe suceder después de la limpieza de esta."
  },
  {
    "objectID": "semana-02.html",
    "href": "semana-02.html",
    "title": "Semana 03/28",
    "section": "",
    "text": "Step 4\n\nData reduction and projection.\nUsing methods to reduce the number of variables.\n\nAnálisis factorial\nAnálisis por componentes\nEtc\n\n\nStep 5\n\nResumir, clasificar, regresión, etc, para las variables.\n\nStep 6\n\nChoosing the data mining algorithms\nSe recomienda establecer mínimo tres modelos para poder compararlos tras su funcionamiento.\nNo escoger solo un módelo.\n\nStep 7\n\nData mining: Buscando patrones de interés\n\nStep 8\n\nIdentificar e interpretar los patrones encontrados.\nLa primera identificación es matemática/numérica/estadística.\n\nStep 9\n\nCombinar la interpretación numérica del paso 8 junto a la expertise sobre el negocio, con el fin de poder darle utilidad a lo hallado."
  },
  {
    "objectID": "semana-02.html#otras-metodologías",
    "href": "semana-02.html#otras-metodologías",
    "title": "Semana 03/28",
    "section": "Otras metodologías",
    "text": "Otras metodologías\n\n\n\n\n\nOtras metodologías conocidas"
  },
  {
    "objectID": "semana-02.html#step-1-entendimiento-del-negocio",
    "href": "semana-02.html#step-1-entendimiento-del-negocio",
    "title": "Semana 03/28",
    "section": "Step 1: “Entendimiento del negocio”",
    "text": "Step 1: “Entendimiento del negocio”\n\nDescribir problema o situación a analizar\n\nEl problema debe expresar una relación entre dos o más variables.\nDebe estar formulado claramente, sin ambigüedad, como pregunta.\nDebe implicar la posiblidad de realizar una prueba empírica o una recolección de datos.\n\n\n\nDefinir los objetivos\n\n¿Qué se desea lograr?\n¿Cómo ayudará al negocio?\nPrincipales áreas interesadas\nOtros objetivos a tener en cuenta.\n¿Qué características debe tener para ser considerado factible?\n¿Qué esperan recibir?\n¿Cómo están pensando utilizar el resultado del análisis de datos?\n¿Con cuánto tiempo contamos?\nObjetivos de analisis de datos\n\nTraducir los objetivos del negocio en objetivos para el análisis.\nEstablecer las métricas o criterios de evaluación de resultados, que serán útiles para el negocio.\nDiseñar un Plan de Análisis de Datos , considerando tiempos, hitos de desarrollo, responsables y fechas para presentación de avances.\nValidar cada paso con el negocio.\n\n\n\n\nDelimitar la población de análisis\n\nLa delimitación principal es en espacio y tiempo.\nUso de los siguientes criterios:\n\nCaso retrospectivo:\n\nInclusión: Características que deben reunir las unidades de observación.\nExclusión: Características que deben estar ausentes en las unidades de observación.\n\nCaso prospectivo:\n\nEliminación: Son aquellas características que aparecen una vez que ya han sido selecctionadas las unidades de observación (surgen en la medida que se realiza el análisis)\n\n\n\n\n\nIdentificar recursos necesarios\n\nPersonas\n\nExperto del negocio\nLíder analítico del proyecto\nEquipo especialista de analistas de datos\nEquipo de accesso e ingeniería de datos\n\nDatos\n\nIdentificar fuentes y dueños de los datos\nPreguntar por la calidad de datos por recibir\n\n¿Cómo se recolectaron los datos?\n¿Cómo se guardaron los datos?\n¿Cómo se llenó la tabla de datos?\n\n\nHerramientas\n\nSoftwares disponibles (libres o con licencia)\nEntorno para selección y preprocesamiento\nEntorno para entrenamiento de modelos\nEntorno para despliegue de modelos\n\n\n\n\nIdentificar limitaciones\n\nLimitaciones del negocio\n\nPosibles restricciones de capacidad operativa\nPoder de acción para utilizar los resultados\nNormativas de la institución o empresa\n\nLimitaciones respecto a datos\n\nSi tendremos acceso a todos los datos\n¿Se tendrá acceso a toda la población definida?\n\nAccesso para que el modelo pueda ser usado por los usuarios relevantes\n\n\nLimitaciones respecto al tiempo\n\nRestricciones en el tiempo de análisis\nTiempo para el despliegue del modelo\n\n\n\n\nOutput del paso 1: Ficha técnica del proyecto de análisis de datos\n\nArchivo en Paideia\n\nLas partes role y area no serán necesario llenarlas.\nProblemática\n\nColocar como pregunta, tipo, “¿Se puede blah …?”\n\nImportante plasmar las limitaciones.\nAcciones de negocio con los resultados\n\nCómo van a desplegar el modelo creado"
  },
  {
    "objectID": "semana-03.html",
    "href": "semana-03.html",
    "title": "Semana 04/04",
    "section": "",
    "text": "Según naturaleza\n\n\nCualitativa (categorías)\nCuantitativa\n\nDiscreta\nContinua\n\n\n\nSegún escala de medida\n\n\nNominal\n\nCualitativa\n\nOrdinal\n\nCualitativa\n\nDe Intervalo\n\nCuantitativa\nSolo existe un zero relativo, cuyo valor no significa ausencia. Simplemente es una referencia dentro de una escala de medida.\nEjemplo: Temperatura\n\nDe razón\n\nCuantitativa\nExiste un cero absoluto que significa ausencia de la unidad."
  },
  {
    "objectID": "semana-03.html#medidas-de-resumen",
    "href": "semana-03.html#medidas-de-resumen",
    "title": "Semana 04/04",
    "section": "Medidas de resumen",
    "text": "Medidas de resumen\n\n\n\n\n\nMedidas básicas de resumen"
  },
  {
    "objectID": "semana-03.html#tendencia-central",
    "href": "semana-03.html#tendencia-central",
    "title": "Semana 04/04",
    "section": "Tendencia central",
    "text": "Tendencia central\nLa media trabaja con la magnitud de los elementos. Se le puede entender como un punto de equilibrio de una distribución.\nLa mediana trabaja con la posición de los elementos (ordenados). Esta divide a la variable en dos partes iguales.\nUna variable ordinal podría no tener asociada una mediana, en caso que la cantidad de datos sea par, pues requeriría realizar un promedio entre ambas categorías centrales.\nLa moda no es muy útil para variables continuas, ya que la frecuencia de un único valor está no definida. Incluso para variables discretas la moda no es tan útil, comparado a la media o mediana.\nDebe tenerse cuidado con transformar variables ordinales en numéricas, si es que se desea aprovechar en un cierto modelo, pero no es recomendable.\nModa, es el valor más frecuente de la variable. Pico más alto de la distribución.\n\n\n\n\n\nTendencia central\n\n\n\n\n\nCuantil\n\nDividen al total de observaciones en m partes iguales.\n\\(\\text{ Cuantil}_i = \\frac{i * n}{m}\\)\n\nCuartil\n\nDividen al total de observaciones en 4 partes iguales.\n\\(\\text{ Q}_i = \\frac{i * n}{4}\\)\n\nDecil\n\nDividen al total de observaciones en 10 partes iguales.\n\\(\\text{ D}_i = \\frac{i * n}{10}\\)\n\n\n\nVariabilidad\n\nRango: máximo - mínimo\nRango Intercuartil:\n\n\\(R = Q_3 - Q_1\\)\n\\(R\\) pequeño implica poca dispersión.\nEs la medida de dispersión recomendada cuando la distribución presenta datos atípicos.\n\nVarianza muestral:\n\n\\(S^2 (x) = \\frac{\\sum_{i=1}^{n}\\left( x_i - \\bar{x} \\right)^2}{n-1}\\)\nEs casi como un promedio de distancias.\nEl término \\(n-1\\) es para que la varianza muetral tienda a la varianza poblacional (estimador insesgado).\n\nDesviación estándar muestral\n\n\\(s(x) = \\sqrt{ \\frac{\\displaystyle{\\sum_{i=1}^{n}} \\left( x_i - \\bar{x} \\right)^2}{n-1}}\\)\n\nCoeficiente de variación\n\n\\(CV(x) = \\frac{s(x)}{\\bar{x}}\\)\nCarece de unidades. Está estandarizado, así que se puede emplear para comparar distribuciones con diferentes escalas de medida.\nMenor coeficiente de variación implica mayor homogeneidad.\nEste valor está sesgado cuando existen valores atípicos en la data. En ese caso, se debe hace un tratamiento especial para los datos atípicos; no basta con usar algo como \\(IQR(x) \\over median(x)\\)\n\n\n\n\nCuando la distribución no presenta valores atípicos (o tiene muy pocos (percentage wise)), y es símetrica, se recomiendan como medidas de resumen la media, varianza y desviación estándar.\nCuando la distribución presenta datos atípicos, y es asimétrica, se recomiendan como medidas de resumen la mediana y el rango intercuartil.\n\n\n\n\nAsimetría\n\nTrata sobre la deformación horizontal.\nCoeficiente de asimetría (AS)\n\nAsimetría negativa: \\(AS < 0\\)\n\nCola jalada hacia la izquierda.\n\nSimétrica: \\(AS = 0\\)\nAsimetría positiva: \\(AS > 0\\)\n\nCola jalada hacia la derecha.\n\n\n\n\n\n\n\n\nAsimetría\n\n\n\n\n\n\nCurtosis\n\nTrata sobre deformación vertical.\nNo hay límite establecido, solo referencias, para saber qué tipo de curtosis está presente.\nMayor coeficiente de curtosis implica mayor deformación vertical.\n\n\n\n\n\n\nCurtosis\n\n\n\n\n\n\n\n\n\nTipos de curtosis\n\n\n\n\nLa curtosis mesocúrtica hace referencia a cuando la distribución se asemeja a la normal.\n\nEn general, cuando vamos a presentar estadísticas, estas deben estar acompañadas de su gráfico respectivo."
  },
  {
    "objectID": "semana-03.html#distribución-marginal",
    "href": "semana-03.html#distribución-marginal",
    "title": "Semana 04/04",
    "section": "Distribución marginal",
    "text": "Distribución marginal\n\nEl estudio de una variable, no analizándola por casos/categorías."
  },
  {
    "objectID": "semana-03.html#distribución-condicional",
    "href": "semana-03.html#distribución-condicional",
    "title": "Semana 04/04",
    "section": "Distribución condicional",
    "text": "Distribución condicional\n\nAnálisis de una variable en función de otras, tratadas como casos/categorías.\nSi una variable \\(X\\) presenta una misma distribución marginal que sus distribuciones condicionales, respecto a una colección \\(Y\\) de categorías, entonces se concluye que estas variables (\\(X\\) e \\(Y\\)) no están relacionadas."
  },
  {
    "objectID": "semana-03.html#hands-on-step2_entendimiento_de_datos.ipynb",
    "href": "semana-03.html#hands-on-step2_entendimiento_de_datos.ipynb",
    "title": "Semana 04/04",
    "section": "Hands-on: step2_entendimiento_de_datos.ipynb",
    "text": "Hands-on: step2_entendimiento_de_datos.ipynb\n\nUno de los primeros pasos tras cargar la data es verificar que cada columna tenga el tipo de dato que le corresponde. Por ejemplo, variables cuantitativas como float, int, etc.\nTambién hay que omitir duplicados en el dataset.\nAl omitir los datos vacíos, no calcular solo cuántos datos vacíos hay, sino también el porcentaje que representan por columna/variable.\nComparando media y mediana de una misma lista de datos, podemos deducir información sobre la presencia de valores atípicos.\n\nHasta entendimiento de datos entrará en el laboratorio 1 de mañana, el cual será individual. Pero, como alumno libre, no tendré nota calificada.\nEl grupo del proyecto final solo puede ser de 4 personas, máximo."
  },
  {
    "objectID": "laboratorio-01.html",
    "href": "laboratorio-01.html",
    "title": "Laboratorio 01",
    "section": "",
    "text": "En los laboratorios 3 y 5 se debe presentar avances del proyecto final."
  },
  {
    "objectID": "laboratorio-01.html#mis-soluciones-del-laboratorio-ipynb",
    "href": "laboratorio-01.html#mis-soluciones-del-laboratorio-ipynb",
    "title": "Laboratorio 01",
    "section": "Mis soluciones del laboratorio (ipynb)",
    "text": "Mis soluciones del laboratorio (ipynb)\n\nPython version\nR version"
  },
  {
    "objectID": "python-r-code.html",
    "href": "python-r-code.html",
    "title": "Paralelismo Python R",
    "section": "",
    "text": "La notación df hace referencia a data frame.\nPrimero mostraré el código en Python, después en R, separando cada pareja de códigos análogos por un segmento de recta."
  },
  {
    "objectID": "python-r-code.html#semana-0404",
    "href": "python-r-code.html#semana-0404",
    "title": "Paralelismo Python R",
    "section": "Semana 04/04",
    "text": "Semana 04/04\n\nData frame manipulation\ndf.shape\ndim(df)\n\ndf.head() \nhead(df)\n\ndf.dtypes \nstr(df)\n\ndf.nombre_columna \ndf$nombre_columna\n\nvariable.astype(variable_type) &nbsp;&nbsp;&nbsp; x.astype('float') \nas.variable_type(variable) &nbsp;&nbsp;&nbsp; as.numeric(x)\n\ndf.drop_duplicates(inplace=True) \ndf <- dplyr::distinct(df, .keep_all = TRUE)\n\ndf.dropna(inplace=True) \ndf <- na.omit(df)\n\nnumpy.mean(df[\"column_name\"] \nmean(df[\"column_name\"])\n\ndf[\"column_name\"].median() \nmedian(df[\"column_name\"])\n\ndf[\"column_name\"].quantile([0.25, 0.50, 0.75]) \nquantile(df[\"column_name\"], c(0.25, 0.50, 0.75))\n\ndf[\"column_name\"].min() \nmin(df[\"column_name\"])\n\ndf[\"column_name\"].max() \nmax(df[\"column_name\"])\n\n(df[\"column_name\"].quantile([0.75])).values - (df[\"column_name\"].quantile([0.25])).values \nIQR(df[\"column_name\"])\n\ndf[\"column_name\"].var() \nvar(df[\"column_name\"])\n\ndf[\"column_name\"].std() \nsd(df[\"column_name\"])"
  }
]